{
  
    
        "post0": {
            "title": "First Blog and Post - Thanks to Fastai",
            "content": "My First Blog . Hello Folks! . Over the past two years, I’ve taken up an interest in Machine Learning and specifically Deep Learning. I found via Perth Machine Learning Group, the fastai course, which is fantastic. . It is primarily the reason for this blog and why I mention it (check out Appendix A and fastpages in github). . . I’m also thinking to record what I know about: . The world of power engineering. | How I get on with investing. | Anything else I find interesting and study. | . This is mainly so that I can point anyone interested to this as a sort of wiki. .",
            "url": "https://stevedoesengineering.github.io/steve-the-engineer/markdown/2021/01/29/My-First-Blog-Post.html",
            "relUrl": "/markdown/2021/01/29/My-First-Blog-Post.html",
            "date": " • Jan 29, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Azure cognitive services   speech to text",
            "content": "Azure Cognitive Service for Speech to Text . Today was an experiment with Azure cognitive tool kit! Its always interesting to see how use of cloud computing goes from the most remote city in the world (Perth, Western Australia). Still the network speeds aren’t terrible in 2021, even with the extra NETFLIX and Streaming traffic due to COVID-19. . REASON: I wanted to try out Azure voice to text and see how well it would work. My intention for this is to take the work out of indexing of video recordings. My ideal would be meeting minutes produced for me without effort at the end of a recording. . SOFTWARE: First thing, I’m doing this using python and as of this post python is up to 3.9.1. As Python is a particularly forgiving language for starting out/rapid prototyping. This version DOES NOT work with Azure cognitive tools so you will need 3.7.6 for compatibility. . So, I’m not sure how you like to arrange things but I like to put versions of python into folders with the packages and run virtualenv [folder address and name], install cmd prompt: virtualenv path/to/folder/VenvNAME. This allows executables with py2exe to only use the packages necessary once you have worked out the nuts and bolts. . This installs the python version on PATH environmental variable into the package which is handy for isolatation and versioning. . With this installed, I was then able to install jupyter and run all the other installs from magics within a notebook (e.g. !pip install pandas) . SETUP OF CHAIN: Once all set up, the following are required: . A suitable video or voice recording to process. | To download FFMPEG source code or a binary depending on your OS and install in a location and add to PATH/system vars. | convert the video or audio via FFMPEG into a .wav format, which is necessary for the Azure API. | Install the azure cognitive Software Development Kit | Optionally, install the spx CLI, which doesn’t require knowing Python, C++ or C# etc (No Code). | Sign up for a free (for 12 months) Azure account. | Subscribe to the Speech service | find API key and Region code for input in python | I also noticed whilst going through the documentation that there is a video indexer API/Service that spits out JSON files for a similar purpose. . 1: Finding a recording shouldn’t be too hard with youtube etc available. 2: FFMPEG website - https://ffmpeg.org/ These guys are awesome, as I’m working on a windows platform I used a binary from Gyan (tip him a coffee if you do!) The executable can be placed in a folder and added to path, I decided (unwisely) to drop it in system32 folder to save hassle. 3: Use of FFMPEG is pretty easy. . I also found that you can use the convert function in VLC using the GUI but this is quite slow and clunky in the long term. Top tip for VLC is to use more options and select convert explicitedly. . 4: The cognitive services are pretty easy to install via jupyter with a magic and pip. . 5: SPX is a “no code” command line tool, which still requires understanding the cmdline etc. So is at best a convienent way if python/jupyter is not an option. . 6: Use an existing microsoft account or create one and pass them your credit card details. 7: Once in the Azure console, the Speech API needs to be added as a service and the key and region found. . 8: Finding the API KEY (there are two, that can be individually regenerated) and REGION . EXPERIENCE USING AZURE COGNITIVE SERVICE - SPEECH TO TEXT (standard models): The whole experience is pretty good. As with all things Machine Learning, the models are a good starting point but need some context. This would be no different to a human. . First go: 1 shot recognition using the example code on the Azure GitHub. It works well but is limited, it will wait 15s or end with a silence after a recognition has triggered. This means that it can’t deal with anything more than a sound bite. This is the reason that the website example that you can upload a file into has a lot of recognition started type notifications. I found that I preferred the second method of continuous recognition, which is a bit heavier but works out better. . Second go: Continuous recognition works on an event handler basis. This means that it has to be explicitly told to stop. This can be by EOF for the recording or via an event. The output from the example shows the recognising working its way from a silence and a phrase. This worked reasonably well. It struggles with multiple language based accents and pronouncation and specific domain wording. This is to be expected, and there is an option for this: custom modelling. . Speaker Recognition: There is also an addition API that can be given 20s clips of an individual and tries to then pick them out in the conversation. I found that this is heavily affected by background noise. . Video indexer: At the next opportunity I’m going to explore this option and report back seperately in its own post. Unfortunately there isn’t a python API (as of this blog). I therefore will likely have to use C#. . Using SPX on CMD: I found that redirection to file was the easiest way to complete a first run. It can take some time, depending on your recording to go through the whole thing and print to file. .",
            "url": "https://stevedoesengineering.github.io/steve-the-engineer/2021/01/29/Azure-Cognitive-Services-Speech-to-Text.html",
            "relUrl": "/2021/01/29/Azure-Cognitive-Services-Speech-to-Text.html",
            "date": " • Jan 29, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://stevedoesengineering.github.io/steve-the-engineer/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://stevedoesengineering.github.io/steve-the-engineer/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}